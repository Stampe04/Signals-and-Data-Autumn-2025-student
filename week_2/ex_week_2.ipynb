{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #00695C; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "# Week 2 - Convolution (or filtering)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This week will focus on convolutions, mostly 2D, discrete convolutions. We will start by focusing on the \"old-school\" specific convolutions, before we in week 3 move onto learned convolutions used in CNN's.\n",
    "\n",
    "The second, optional module, focuses on entropy and cross entropy, which may be useful for understanding some parts of next week, but as with all optional parts, will not be material for the exam.\n",
    "\n",
    "**At the end of this week, you should be able to:**\n",
    "\n",
    "- Explain how padding works to perserve image dimensions during convolution\n",
    "- Explain different kinds of padding like constant, reflect, replicate, etc.\n",
    "- Explain how 2d convolutions are performed on images\n",
    "  - Be able to manually run or implement an algorithm that, given a kernel and an image or array, convolves the image with the kernel\n",
    "- Have a rough understand of the differences between cross correlation and convolution.\n",
    "- Know how you can construct different kind of kernels for specific purposes like blurring, edge enhancement, sharpening, etc.\n",
    "\n",
    "**Optional**:\n",
    "- Understand what entropy is and how it relates to the outcome probabilities of a random variable, for example when it is maximized or minimized\n",
    "- Calculate the theoretical entropy of a given random variable\n",
    "- Calculate the empirical entropy given random variates\n",
    "- Understand how the cross-entropy relates to the entropy, for example when it is maximized or minimized\n",
    "- Calculate the theoretical cross-entropy between two distributions\n",
    "---\n",
    "\n",
    "\n",
    "We are going to use images in the form of multidimensional arrays of data (a 2D matrix for a grayscale image and  3 2D matrices in case of a RGB image) and the kernel will be a 2D matrix (usually square with an odd number of rows/columns). Therefore, we will talk about 2D convolution.\n",
    "\n",
    "If we have our input image $f_{in}$ (which we assume is of size $N \\times N$ pixels) and a kernel K, the convolution is defined by:\n",
    "\n",
    "$$f_{out}(x,y)=K*f_{in}(x,y)= \\sum^N_{s=-N}\\sum^N_{t={-N}}K(s,t)f_{in}(x-s,y-t)$$\n",
    "\n",
    "where $f_{out}(x,y)$ is the value of the pixel $(x,y)$ of the output image $f_{out}$. \\\\\n",
    "\n",
    "In the discrete case, which is what we consider, convolution considers the elementwise product between the **kernel** (sometimes called a filter), and the **sub-image** region considered. The following video shows how this can look with a given image and kernel. Note that the below case uses **mirror** or **symmetric** padding.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <video controls src = \"images/2dconv.mp4\" width = \"500\" height = \"400\">\n",
    "</div>\n",
    "\n",
    "Also note, that in the below case, we assume the kernel **is flipped**. Though,since it is symmetric, we cannot tell the difference between it and a flipped kernel...\n",
    "\n",
    "---\n",
    "\n",
    "## Cross correlation or Convolution?\n",
    "\n",
    "In these exercises we are technically going to consider **cross correlation** as a simplified technique of the convolution. Cross correlation is almost exactly the same as convolution, except here, we don't \"flip\" the kernel in our operation, leading to the formula looking like:\n",
    "\n",
    "$$f_{out}(x,y)=K*f_{in}(x,y)= \\sum^N_{s=-N}\\sum^N_{t={-N}}K(s,t)f_{in}(x+s,y+t)$$\n",
    "\n",
    "I.E: almost exactly the same, just with a $+$ where there used to be a \"-\". Practically, this equates to \"flipping\" the filter you pass over a signal, in our case an image. Practically, you don't need to worry about this whole \"flipping of the kernel\", it will rarely be relevant in machine learning, and mostly exists in pure signal processing. \n",
    "\n",
    "<!-- However, if you're curious, the below video shows the simple difference between cross correlation and convolution in a 1D case. (Note, that this video also shows the **continuous** case, as opposed to what we work with, which is the **discrete** case of convolution and cross correlation) -->\n",
    "\n",
    "<!-- <div style=\"text-align: center;\">\n",
    "    <video controls src = \"images/cross_corr_vs_conv_1d.mp4\" width = \"500\" height = \"400\">\n",
    "</div> -->\n",
    "\n",
    "---\n",
    "\n",
    "NOTE: ML engineers are lazy beyond what's right, and often don't care about the nuances of mathematics. In many ML libraries, cross correlation operations will be mislabeled as \"convolution\", despite not flipping the kernel. This is for example the case in [pytorch's \"Conv2d\"](https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html). The point is, don't worry too much about it when doing machine learning, just know the difference.\n",
    "\n",
    "In these exercises, we will similarily be \"lazy\" and not ask you to flip the kernel, since this just makes it all that much easier.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T12:04:10.081178Z",
     "start_time": "2024-09-05T12:04:10.067175Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "\n",
    "from scipy.signal import convolve2d as scipy_conv2d, convolve as scipy_conv1d, correlate2d\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 1: Understanding padding\n",
    "\n",
    "It's a good idea to first get a handle on what padding actually is. Usually we work with the following types of padding:\n",
    "\n",
    "- Reflect (sometimes called mirror)\n",
    "- Edge (sometimes called replicate)\n",
    "- Constant (a common special case i zero-padding)\n",
    "- Wrap (sometimes called circular padding)\n",
    "\n",
    "#### **1.1. Below the different padding types are shown in action using the np.pad function, give an explanation for what each type appears to do to the image**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **1.2. In the code, we don't explicitly state a value for the constant type pad, what does the default value appear to be? What does this equate to?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image_path = os.path.join(\"images\", \"kb_grayscale.jpg\")\n",
    "image_gray = np.array(Image.open(image_path))\n",
    "\n",
    "# In this case, we use a fixed amount of padding for all dimensions of the image...\n",
    "padding_size = [[100, 10], [30, 50]]  # ((top, bottom), (left, right))\n",
    "\n",
    "pad_types = [\"constant\", \"reflect\", \"wrap\", \"edge\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for ax, pad_type in zip(axes, pad_types):\n",
    "    # Create padded image\n",
    "    image_padded = np.pad(image_gray, padding_size, pad_type)\n",
    "\n",
    "    # Display padded image    \n",
    "    ax.imshow(image_padded, cmap=\"gray\")\n",
    "    ax.set_title(f\"Padded: {pad_type}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 2: Implementing convolution\n",
    "\n",
    "A typical first exercise is implementing your own convolution function. Depending on how you do it, it can end up being a bunch of for loops and if-statements. While we won't work with 1d convolution untill around week 6, it is also a good exercise to implement it first to get a hang for how 2d convoltuion can be implemented. Remember, the formula for convolution is as follows:\n",
    "\n",
    "$$f_{out}(x,y)=K*f_{in}(x,y)= \\sum^N_{s=-N}\\sum^N_{t={-N}}K(s,t)f_{in}(x-s,y-t)$$\n",
    "\n",
    "And it needs to do what is essentially shown in the video:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <video controls src = \"images/2dconv.mp4\" width = \"500\" height = \"400\">\n",
    "</div>\n",
    "\n",
    "\n",
    "#### **2.1. üíª Complete the function below to implement 1d convolution, you should not add any padding to the final \"image\"**\n",
    "\n",
    "#### **2.2. üíª Complete the function below to implement 2d convolution, you should not add any padding to the final image**\n",
    "\n",
    "#### **2.3. üíª Test 1d and 2d convolution implementations against the package solution using the unittesting cell two cells below**\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T12:04:11.543026Z",
     "start_time": "2024-09-05T12:04:11.529033Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convolution1d(signal, kernel):\n",
    "    \"\"\"\n",
    "    1d convolution function\n",
    "    \"\"\"\n",
    "\n",
    "    assert kernel.shape[0] % 2 == 1, 'Kernel length must be odd for this convolution function'\n",
    "    \n",
    "    # Flip the kernel - So we don't need to worry about that...\n",
    "    kernel = np.flip(kernel)\n",
    "    \n",
    "    # Get dimensions of both signal and kernel\n",
    "    signal_length = signal.shape[0]\n",
    "    kernel_length = kernel.shape[0]\n",
    "    \n",
    "    # Compute output length\n",
    "    output_length = signal_length - kernel_length + 1\n",
    "    \n",
    "    # Initialize the array which will hold the output\n",
    "    output = ...\n",
    "    \n",
    "    # Perform 1D convolution\n",
    "    for i in range(output_length):\n",
    "\n",
    "        # Get the sub-region of the signal that the kernel focuses on\n",
    "        sub_region = ...\n",
    "        \n",
    "        # Multiply these with the corresponding values of the kernel\n",
    "        sub_region_kernelized = ...\n",
    "\n",
    "        # Sum these values and set the corresponding pixel in the output signal\n",
    "        output[i] = ...\n",
    "    \n",
    "    return output\n",
    "    \n",
    "\n",
    "def convolution2d(image, kernel):\n",
    "    assert kernel.shape[0] % 2 == 1 and kernel.shape[1] % 2 == 1, 'kernel must be an odd number for this convolution function'\n",
    "    \n",
    "    # Flip the kernel - So we don't need to worry about that...\n",
    "    # Here we have to flip both \"up-down\" and \"left-right\"\n",
    "    kernel = np.flipud(np.fliplr(kernel))\n",
    "    \n",
    "    # Get the dimensions of the image and the kernel\n",
    "    image_height, image_width = image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    \n",
    "    # Compute the output dimensions\n",
    "    output_height = image_height - kernel_height + 1\n",
    "    output_width = image_width - kernel_width + 1\n",
    "    \n",
    "    # Initialize the output matrix which will hold the convolved pixel values\n",
    "    output = np.zeros((output_height, output_width))\n",
    "    \n",
    "    # Perform 2D convolution\n",
    "    # Loop over all values in the height of the output image...\n",
    "    for i in range(output_height):\n",
    "        # And all values in the width of the output image\n",
    "        for j in range(output_width):\n",
    "            # Get the 'sub-image' that the kernel currently focuses on\n",
    "            sub_image = ...\n",
    "\n",
    "            # Multiply each value in this sub image with the respective values of the kernel\n",
    "            sub_image_kernelized = ...\n",
    "\n",
    "            # Sum these values and set the corresponding pixel in the output image\n",
    "            output[...] = ...\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class Convolve2dtest(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"\"\"\"\n",
    "        self.own_conv_fun = convolution2d\n",
    "        self.scipy_conv_fun = scipy_conv2d\n",
    "        self.f_in = np.array([\n",
    "            [0,1,0],\n",
    "            [0,2,0],\n",
    "            [0,3,0]\n",
    "        ])\n",
    "        self.w = np.array([[1,2,1]])\n",
    "\n",
    "    def test_convolve2d_valid(self):\n",
    "        \"\"\"\n",
    "        With \"valid\" padding in scipy_conv2d, it will create an image without padding it, possibly changing the output dimensions along the way\n",
    "        \n",
    "        TODO: Valid docstrings here\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        own_output = self.own_conv_fun(self.f_in, self.w)\n",
    "        scipy_output = self.scipy_conv_fun(self.f_in, self.w, mode=\"valid\")\n",
    "        \n",
    "        self.assertTrue(\n",
    "                        np.all(own_output == scipy_output),\n",
    "                        msg=f\"Scipy output: \\n {scipy_output} \\n does not match own implementation output: \\n {own_output}\"\n",
    "                        )\n",
    "\n",
    "    def test_convolve2d_same(self):\n",
    "        \"\"\"\n",
    "        If scipy_conv2d mode is set to \"same\" it will zero-pad to get the same number of output as input dimensions\n",
    "\n",
    "        TODO: Valid docstrings here\n",
    "        \"\"\"\n",
    "\n",
    "        # Pad the input image with enough columns to create a same output image\n",
    "        f_padded = np.pad(self.f_in, [(0, 0), (1,1)], constant_values=0)\n",
    "\n",
    "        own_output = self.own_conv_fun(f_padded, self.w)\n",
    "        scipy_output = self.scipy_conv_fun(self.f_in, self.w, mode=\"same\")\n",
    "        \n",
    "        self.assertTrue(\n",
    "                        np.all(own_output == scipy_output),\n",
    "                        msg=f\"Scipy output with valid convolution: \\n {scipy_output} \\n does not match own implementation output: \\n {own_output}\"\n",
    "                        )\n",
    "\n",
    "\n",
    "class Convolve1dtest(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        Set up the input signal and kernel for 1D convolution tests.\n",
    "        Assign both the custom and reference convolution functions.\n",
    "        \"\"\"\n",
    "        self.own_conv_fun = convolution1d\n",
    "        self.scipy_conv_fun = scipy_conv1d\n",
    "\n",
    "        # 1D input signal\n",
    "        self.f_in = np.array([0, 1, 2, 3, 4])\n",
    "\n",
    "        # 1D kernel\n",
    "        self.w = np.array([1, 0, -1])\n",
    "\n",
    "    def test_convolve1d_valid(self):\n",
    "        \"\"\"\n",
    "        Test 1D convolution with 'valid' mode.\n",
    "        This mode performs convolution without padding, resulting in a smaller output.\n",
    "        \"\"\"\n",
    "        own_output = self.own_conv_fun(self.f_in, self.w)\n",
    "        scipy_output = self.scipy_conv_fun(self.f_in, self.w, mode=\"valid\")\n",
    "\n",
    "        self.assertTrue(\n",
    "            np.allclose(own_output, scipy_output),\n",
    "            msg=f\"Scipy output (valid):\\n{scipy_output}\\ndoes not match own output:\\n{own_output}\"\n",
    "        )\n",
    "\n",
    "    def test_convolve1d_same(self):\n",
    "        \"\"\"\n",
    "        Test 1D convolution with 'same' mode.\n",
    "        Since the custom function does not handle padding internally,\n",
    "        we manually pad the input to match scipy's 'same' output dimensions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate padding size: (kernel_size - 1) // 2 on each side\n",
    "        pad_width = (self.w.size - 1) // 2\n",
    "        f_padded = np.pad(self.f_in, (pad_width, pad_width), constant_values=0)\n",
    "\n",
    "        own_output = self.own_conv_fun(f_padded, self.w)\n",
    "        scipy_output = self.scipy_conv_fun(self.f_in, self.w, mode=\"same\")\n",
    "\n",
    "        self.assertTrue(\n",
    "            np.allclose(own_output, scipy_output),\n",
    "            msg=f\"Scipy output (same):\\n{scipy_output}\\ndoes not match own output:\\n{own_output}\"\n",
    "        )\n",
    "\n",
    "class CustomTestResult(unittest.TextTestResult):\n",
    "    def addSuccess(self, test):\n",
    "        super().addSuccess(test)\n",
    "        print(f\"‚úÖ SUCCESS: {test}\")\n",
    "\n",
    "    def addFailure(self, test, err):\n",
    "        super().addFailure(test, err)\n",
    "        print(f\"‚ùå FAILURE: {test}\\n{err[1]}\")\n",
    "\n",
    "    def addError(self, test, err):\n",
    "        super().addError(test, err)\n",
    "        print(f\"‚ö†Ô∏è ERROR: {test}\\n{err[1]}\")\n",
    "\n",
    "class CustomTestRunner(unittest.TextTestRunner):\n",
    "    def _makeResult(self):\n",
    "        return CustomTestResult(self.stream, self.descriptions, self.verbosity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Running tests to check own convolution1d function against scipy...\")\n",
    "    CustomTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(Convolve1dtest))\n",
    "\n",
    "\n",
    "    print(\"Running tests to check own convolution2d function against scipy...\")\n",
    "    CustomTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(Convolve2dtest))\n",
    "\n",
    "except NameError:\n",
    "    print(\"ERROR not find unit-testing suite, did you run the (hidden) cell right above?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 3: Kernel design\n",
    "\n",
    "When using convolution, we can manually design kernels that apply a certain effect to our images. This is still  large part of many image processing techniques still used today. Initially, we will work with three different kernels:\n",
    "\n",
    "  $$ F_{blurry} = \\frac{1}{9} \\left[ {\\begin{array}{ccc} 1&1&1\\\\1&1&1\\\\1&1&1 \\end{array}} \\right] \\quad F_{sharp} = \\left[ {\\begin{array}{ccc}0&-1&0\\\\-1&7&-1\\\\0&-1&0\\end{array}} \\right] \\quad F_{edge} = \\left[ {\\begin{array}{ccc}0&1&0\\\\1&-4&1\\\\0&1&0\\end{array}} \\right] $$\n",
    "\n",
    "#### **3.1 The kernels obviously serve to either blur an image, sharpen an image, and enhance the edges of an image respectively. Give some inuition on why they have this effect. For example, why deos the first kernel blur the image?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "#### **3.2. üíª Right now, all the kernels below do nothing to the image, rewrite them to correctly implement the blurry, sharpen, and edge kernels**\n",
    "\n",
    "#### **3.3. üíª What happens with the blurry kernel? Is there a way to make it blur more? Try implementing that**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **3.4. üíª Using your own convolve2d function is probably a bit slow. Test the speed of your own implementation of convolution against that of scipy's. Potentially consider whether this can be improved**\n",
    "\n",
    "#### **3.5. üíª Play around a bit with the different images to try to answer some of the following questions**\n",
    "\n",
    "- **What happens if you sharpen an image after blurring it?**\n",
    "- **What happens if you edge-enhance an image after sharpening?**\n",
    "- **How do the different kernels affect the maximum and minimum values of the image?**\n",
    "- **How do kernels that affect the maximum and minimum values of an image appear to change the image visually? Is there a way to remidy this?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the image\n",
    "image_path = os.path.join(\"images\", \"kb_grayscale.jpg\")\n",
    "image_gray = np.array(Image.open(image_path))\n",
    "\n",
    "kernel_types = [\"none\", \"blur\", \"sharp\", \"edge\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Define the different kernels\n",
    "kernel_none = np.zeros((3,3))\n",
    "kernel_none[1,1] = 1\n",
    "\n",
    "kernel_blur = np.array([[0,0,0],[0,1,0],[0,0,0]])\n",
    "\n",
    "kernel_sharp = np.array([[0, -1, 0], [-1, 7, -1], [0, -1, 0]])\n",
    "\n",
    "kernel_edge = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
    "\n",
    "kernels = [kernel_none, kernel_blur, kernel_sharp, kernel_edge]\n",
    "\n",
    "# Normalize image to float values beteen 0 and 1\n",
    "image_float = image_gray / float(np.max(image_gray))\n",
    "\n",
    "time_taken = 0\n",
    "\n",
    "for ax, kernel_type, kernel in zip(axes, kernel_types, kernels):\n",
    "    t = time()\n",
    "    # Perform convolution\n",
    "    convolved_image = convolution2d(image_float, kernel)\n",
    "    time_taken += time() - t\n",
    "\n",
    "    # Display convolved image    \n",
    "    ax.imshow(convolved_image, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"Convolved with {kernel_type}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"All convolutions completed after around {time_taken:.4f} seconds, can scipy beat this?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 4: Sobel filter\n",
    "\n",
    "In this exercise you are going to apply a more sophisticated edge detection filter than the one you used in the previous exercise. We will apply a Sobel filter to the original image. The Sobel filter (also known as Sobel operator https://en.wikipedia.org/wiki/Sobel_operator) is composed by these two different filters:\n",
    "\n",
    "$$ F_{v} = \\left[ {\\begin{array}{ccc}-1&0&1\\\\-2&0&2\\\\-1&0&1\\end{array}} \\right] \\quad F_{h} = \\left[ {\\begin{array}{ccc}-1&-2&-1\\\\0&0&0\\\\1&2&1\\end{array}} \\right]$$ \n",
    "\n",
    "These two filter, when convoluted with an image, are approximating the derivatives for the vertical and horizontal changes. Indeed, we have that we have that the value of the derivative is high when there is an high difference between neighbours pixels - this is exactly where an edge is. \n",
    "\n",
    "If we let $G_{v}$ and $G_{h}$ denote the resulting filtered images obtained by the convolution between $F_{v}$ and $F_{h}$ respectively with the original image, we can use them to compute an approximation of the gradient for each point in the image by computing a sort of \"combined Sobel filter\":\n",
    "\n",
    "$$ G = \\sqrt{ G_{v}^2 + G_{h}^2} $$\n",
    "\n",
    "\n",
    "#### **4.1. üíª Right now, all kernels are standard \"nothing\" kernels. Change these to be the sobel vertical, sobel horizontal, and combined sobel respectively**\n",
    "\n",
    "#### **4.2. Comment on the resulting images.**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **4.3. How does the combined sobel filter for edge detection compare to the edge detection filter in the previous exercise? Why is it potentially inferior or superior?**\n",
    "\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "#### **4.4. üíª Remove the flipping of the kernel in your convolution function, thus changing it to cross-correlation, or use `scipy.signal.correlate2d`, which does not flip the kernel, how does the result change?** HINT: You may have to plot all three images below one another to see a difference, so just copy paste the whole cell with cross-correlation instead\n",
    "\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T12:04:20.782874Z",
     "start_time": "2024-09-05T12:04:20.068296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reload the image\n",
    "image_path = os.path.join(\"images\", \"kb_grayscale.jpg\")\n",
    "image_gray = np.array(Image.open(image_path))\n",
    "image_float = image_gray / float(np.max(image_gray))\n",
    "\n",
    "# Change Sobel kernels here to reflect true sobel kernel\n",
    "sobel_kernel_v = np.array([[0,0,0],[0,1,0],[0,0,0]])\n",
    "sobel_kernel_h = np.array([[0,0,0],[0,1,0],[0,0,0]])\n",
    "\n",
    "# Create two convolutions by convolving image with the two sobel kernles\n",
    "G_v = ...\n",
    "G_h = ...\n",
    "\n",
    "# Create combined Sobel image\n",
    "G  = ...\n",
    "\n",
    "sobel_names = [\"Sobel Vertical\", \"Sobel Horizontal\", \"Combined Sobel\"]\n",
    "sobels = [G_v, G_h, G]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for ax, convolved_image, name in zip(axes, sobels, sobel_names):\n",
    "    ax.imshow(convolved_image, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 5: RGB images\n",
    "\n",
    "The exact same methods you've learned up until now can also be used on RGB images, or indeed images with **any number of channels**.\n",
    "\n",
    "Note: Last time, we mentioned that an image with a single channel will appear gray. This is still true, even though there are single-channel plots below that appear red, green, and blue. The reason for this is just what color map we choose to plot with. In this case, we want to show the effect on each color individually, so we plot the single-channel images as if they are values that represent red, green, and blue instead of simply representing luminosity.\n",
    "\n",
    "\n",
    "#### **5.1. üíª Try using the blur, sharpen and edge enhancement kernel on each channel respectively. How does each channel react to convolution with these kernels?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "#### **5.2. üíª Make a combined image by using each of the color channels after convolution, does this look the way you expect?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **5.3. üíª Play around with mixing and matching different kernels across different channels and combining these in different ways.**\n",
    "\n",
    "\n",
    "#### **5.4. Can you think of any cases where you would want to apply channel-wise convolutions independently, so convolution with one kernel to one channel, and another kernel to another channel?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T12:07:57.756577Z",
     "start_time": "2024-09-05T12:07:52.716173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load image\n",
    "img_rgb_path = os.path.join(\"images\", \"field.png\")\n",
    "img_rgb = np.array(Image.open((img_rgb_path)))\n",
    "\n",
    "img_rgb_float = img_rgb / img_rgb.max(axis=(0, 1)).astype(np.float32)\n",
    "\n",
    "# Show the default image before convolution\n",
    "plt.imshow(img_rgb_float, cmap=\"viridis\")\n",
    "plt.title(f\"Original RGB image with shape {img_rgb.shape}\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define the filters of the different channels\n",
    "r_filter = kernel_sharp\n",
    "g_filter = kernel_sharp\n",
    "b_filter = kernel_sharp\n",
    "\n",
    "# Extract the various channels\n",
    "r_channel = img_rgb_float[:, :, 0]\n",
    "g_channel = img_rgb_float[:, :, 1]\n",
    "b_channel = img_rgb_float[:, :, 2]\n",
    "\n",
    "# Convolve each channel with the given filter\n",
    "r_fil = scipy_conv2d(r_channel, r_filter)\n",
    "g_fil = scipy_conv2d(g_channel, g_filter)\n",
    "b_fil = scipy_conv2d(b_channel, b_filter)\n",
    "\n",
    "\n",
    "# Plot the result of each convolution\n",
    "fig = plt.figure(figsize = (20, 30))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.imshow(r_channel, cmap=\"Reds\", vmin=0, vmax=1)\n",
    "plt.title(\"Red Channel\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.imshow(r_fil, cmap=\"Reds\", vmin=0, vmax=1)\n",
    "plt.title(\"Red channel after convolution\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.imshow(g_channel, cmap=\"Greens\", vmin=0, vmax=1)\n",
    "plt.title(\"Green channel\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.imshow(g_fil, cmap=\"Greens\", vmin=0, vmax=1)\n",
    "plt.title(\"Green channel after convolution\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(4, 2, 5)\n",
    "plt.imshow(b_channel, cmap=\"Blues\", vmin=0, vmax=1)\n",
    "plt.title(\"Blue channel\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(4, 2, 6)\n",
    "plt.imshow(b_channel, cmap=\"Blues\", vmin=0, vmax=1)\n",
    "plt.title(\"Blue channel after convolution\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(4, 2, 7)\n",
    "channels = np.stack((r_channel, g_channel,b_channel,), axis=-1)\n",
    "plt.imshow(channels, cmap=\"viridis\", vmin=0, vmax=1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Sum the result of all convolutions\n",
    "final = np.stack((r_fil, g_fil, b_fil), axis=-1)\n",
    "plt.subplot(4, 2, 8)\n",
    "plt.imshow(final, cmap=\"viridis\", vmin=0, vmax=1)\n",
    "plt.title(\"All channels after convolution\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #00695C; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "## $\\star$ A primer on (Cross)-Entropy\n",
    "\n",
    "*This is an optional subject*\n",
    "\n",
    "Entropy can often best be considered as a measure of uncertainty, or an expected degree of \"surprise\" in observing the outcome of a random variable. The formula, as unintuitive as it is, is the following:\n",
    "\n",
    "$$H(X) = - \\sum^{N}_{i = 1}p(X = x_i) \\log_2(p(X = x_i))$$\n",
    "\n",
    "(Note here, that we consider only the discrete case of entropy.) (Also note, we use $log_2$, which we will write as $\\log$ from hereon out)\n",
    "\n",
    "The formula says, that the entropy of a random variable, is equal to the sum of the product of the probability for each possible outcome and the log of that probability.\n",
    "\n",
    "This formula perhaps doesn't make much sense in and of itself, so instead it makes sense to consider the following example: We have our friend throw a fair six-sided die, which we then need to guess the result of using the least number of yes/no questions. Since the dice is fair, the best method here is constantly trying to **halve** the number of possible options the dice can land on. First by asking a question like *\"Is the result 1, 2 or 3?\"*. This strategy is illustrated below:\n",
    "\n",
    "<p align=\"center\">\n",
    " <img src=\"images/dice_throw_entropy.png\" width=\"400\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "As you can see, using this , we are sometimes lucky and get the correct answer after only 2 questions, however, somtimes we need to use 3. This brings us to the informal definition of entropy: \n",
    "\n",
    "<p align=\"center\">\n",
    "    <strong>Given that you ask the most informative questions possible, how many yes/no questions do you on average need to guess the result of random variable?</strong>\n",
    "</p>\n",
    "\n",
    "\n",
    "Do note, when we say \"**most informative questions**\", we mean that we will always try to ask the questions that most quickly bring us to a correct guess of the random variable, even if this means just guessing a value right off the bat. For example if our friend used a weighted die with a $50\\%$ chance of landing on a 6, the most informative first question would be \"*Is it 6?*\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 6: Introductory entropy calculation\n",
    "\n",
    "As always, it's useful to start wtih some manual calculations to get a feel for how the formulas actually work...\n",
    "\n",
    "#### **6.1. Using the given formula, calculate the entropy of a fair, six-sided die**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "#### **6.2. Likewise, calculate the entropy of a fair, eight-sided die. How does this result compare to right above?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **6.3 Explain how Entropy can be seen as a degree of \"surprise\" associated with the outcome of random variables**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "#### **6.4. üíª Complete the function in the cell below to calculate the entropy of a bernoulli random variable based on its p parameter. HINT: You can think of the bernoulli random variable as a variable denoting a sort of coin flip, with p being the probabilty of a getting heads.**\n",
    "\n",
    "\n",
    "#### **6.5. üíª Complete the function in the cell below to calculate the empirical entropy of a random variable based on recieved random variates**\n",
    "\n",
    "#### **6.6. Examine the plot of the theoretical and empirical entropy, do they correspond to what you would expect? Why / Why not?** \n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theoretical_bernoulli_entropy(p):\n",
    "    \"\"\"\n",
    "    Compute the entropy of a bernoulli random variable based on its p parameter.\n",
    "\n",
    "    Args:\n",
    "        p (float): Parameter indicating the paobility of a success\n",
    "\n",
    "    Returns:\n",
    "        H (float): Entropy of the bernoulli random variable with the given parameter p\n",
    "    \"\"\"\n",
    "\n",
    "    H = ...\n",
    "\n",
    "    return H \n",
    "\n",
    "def empirical_entropy(random_variates):\n",
    "    \"\"\"\n",
    "    Compute the empirical entropy of a set of random variates\n",
    "\n",
    "    Args:\n",
    "        random_variates (np.ndarray): Array of numbers indicating the outcome of a random variable\n",
    "\n",
    "    Returns:\n",
    "        H (np.ndarray): A numpy array containing the entropy of each of the random variables\n",
    "    \"\"\"\n",
    "    # Compute the empirical probability mass function\n",
    "    # So the probabilities of each outcome based the outcomes\n",
    "    p = ...\n",
    "    \n",
    "    # Remove zero probabilities - in case any outcome is not represented\n",
    "    p = p[p > 0]\n",
    "    \n",
    "    # Compute the entropy\n",
    "    H = ...\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate values for the p parameter in our bernoulli variable\n",
    "p_values = np.linspace(0.001, 0.999, 500)\n",
    "\n",
    "# Calculate the theoretical entropy of these values\n",
    "entropy_values = theoretical_bernoulli_entropy(p_values)\n",
    "\n",
    "# Generate random samples from a binomial distribution (numpy does not have bernoulli, as it is just a special case of the binomial anywaysl)\n",
    "random_variates = np.array([np.random.binomial(1, p, 1000) for p in p_values])\n",
    "# Calculate empirical entropies of the generated random variates by applying our function to each element in the array\n",
    "empirical_entropies = list(map(empirical_entropy, random_variates))\n",
    "\n",
    "\n",
    "# Plot both theoretical and empirical entropy\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# First subplot: Entropy as a function of p\n",
    "axs[0].plot(p_values, entropy_values, label='Entropy H(p)')\n",
    "axs[0].set_title('Theoretical entropy of a Bernoulli Random Variable')\n",
    "axs[0].set_xlabel('Probability p')\n",
    "axs[0].set_ylabel('Entropy H(p)')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Second subplot: Empirical entropy as a function of p\n",
    "axs[1].plot(p_values, empirical_entropies, label='1 - p', color='r')\n",
    "axs[1].set_title('Empirical entropy of a Bernoulli Random Variable')\n",
    "axs[1].set_xlabel('Probability p')\n",
    "axs[1].set_ylabel('Entropy H(p)')\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 7: Categorical entropy calculation\n",
    "\n",
    "Calculating the entropy of a bernoulli random variable is maybe a bit trivial, but the same functions we just made, can be generalized to categorical variables.\n",
    "\n",
    "#### **7.1. Run the cell and insepect the output what do you notice when comparing entropy across the different distributions?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "#### **7.2. Why can you say that the purple distribution has a lower degree of \"surprise\" on average?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **7.3 Imagine the categorical distributions represent the output probabilties of a ML classifier after being shown a datapoint with 4 possible classes, I.E: a probability of 25% for class 2, means that the classifier thinks there is a 25% probability that the datapoint belongs to class 2. Which of the categorical distributions would you as an ML engineer be most happy with?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a few categorical distributions - Feel free to replace some of these with your own!\n",
    "cat1 = np.array([0.1, 0.2, 0.3, 0.4])  # 4 categories\n",
    "cat2 = np.array([0.25, 0.25, 0.25, 0.25])  # Uniform distribution\n",
    "cat3 = np.array([0.05, 0.15, 0.6, 0.2])  # Slightly skewed towards category 3\n",
    "cat4 = np.array([0.05, 0.05, 0.05, 0.85])  # Dominated by category 4\n",
    "\n",
    "# Add to list and create dummy category names\n",
    "categorical_probabilities = [cat1, cat2, cat3, cat4]\n",
    "categories = np.arange(4)\n",
    "\n",
    "# Draw random samples with the categorical distributions as probabilities\n",
    "categorical_samples = [np.random.choice(categories, size=1000, p=cat) for cat in categorical_probabilities]\n",
    "\n",
    "# Calculate empirical entropies\n",
    "categorical_entropies = list(map(empirical_entropy, categorical_samples))\n",
    "\n",
    "\n",
    "# Plot each categorical distribution along with its given empirical entropy\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (axis, cat_probabilities, cat_entropy, color) in enumerate(zip(axes, categorical_probabilities, categorical_entropies, ['b', 'g', 'r', 'purple'])):\n",
    "    axis.bar(categories, cat_probabilities, color=color)\n",
    "    axis.set_title(f\"Cat {i+1} Empirical Entropy: {cat_entropy:.2f}\")\n",
    "    axis.set_xlabel(\"Category\")\n",
    "    axis.set_ylabel(\"Probability\")\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #00695C; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "## $\\star$ Cross entropy\n",
    "\n",
    "Now, we assume you at least have an idea of what entropy, lets move on to Cross-entropy, which looks much like the entropy:\n",
    "\n",
    "$$H(p, q) = - \\sum^N_{i = 1} p(x_i) \\log(q(x_i))$$\n",
    "\n",
    "What really changed? With the regular formula for entropy we compare a variable's probabilities to the log of themselves. Now, we compare the values of one probability distribution, $p$, to the values of a another probability distribution $q$.\n",
    "\n",
    "We do not show it explicitly, but assume we have some random variable $X$, whose true probability distribution $p$ we attempt to approximate with some other probability distribution $q$.\n",
    "\n",
    "Why is this useful? Two reasons mainly:\n",
    "\n",
    "1. It gives us a very intuitive way of evaluating the performance of models that output probability distributions for classification, like neural networks.\n",
    "2. It has some nice mathematical properties that directly ties it to multinomial logistic regression. (Which also gives it the cursed name of **\"Negative Binomial Log-Likelihood\"** (please don't ever call it that, it is the **Cross-Entropy**))\n",
    "\n",
    "Because of its properties (especially, its relation to the \"[Kullback-Liebler (KL) Divergence](https://johfischer.com/2021/12/31/intuitive-explanation-of-the-kullback-leibler-divergence/)\"), the cross-entropy can be seen as measuring the \"total cost\" (in bits of information) of representing $p$ (the correct probability distribution) with $q$ (the approximate probability distribution)... optimal for modelling in ML. Why the **total** cost? Because the cross-entropy (unlike the KL-divergence) incorporates the intrinsic entropy of the variable in question. \n",
    "\n",
    "Indeed, the cross-entropy is actually \"just\" the sum of the KL divergence (how different our approximating distribution is from the true distribution), and the entropy (how uncertain the true distribution is). Therefore, when approximating a given distribution with some other distribution, the cross-entropy denotes how much uncertainty we are left with, or how much information we have to \"pay\" (usually paid in guesses) to get correct clasifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #545454; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "### Exercise 8: Calculating cross entropy\n",
    "\n",
    "In the cell below, we have a couple of categorical distributions, but this time, we have another *5th* distribution, used to approximate them. \n",
    "\n",
    "#### **8.1. In general, what appears to contribute to higher values of the cross entropy**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **8.2. Can we reasonably expect any of the original categorical distributions to always have a higher cross entropy, no matter the distribution used to approximate them?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "#### **8.3. Subtract each distribution's entropy from the calculated cross-entropy, what do the results show? What does this demonstrate?**\n",
    "\n",
    "<span style=\"background-color: #00590D; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "Your answer here $\\dots$\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theoretical_cross_entropy(p, q):\n",
    "    \"\"\"\n",
    "    Calculate the theoretical cross-entropy between two categorical distributions\n",
    "\n",
    "    Args:\n",
    "        p (list[float]): Probabilities for each catetory in the approximated distribution\n",
    "        q (list[float]): Probabilities for each catetory in the approximating distribution \n",
    "    \n",
    "    Returns:\n",
    "        H (float): The theoretical cross entropy of the two input distributions\n",
    "    \"\"\"\n",
    "    return -np.sum(p * np.log2(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximating distribtion - We will use this to calculate the cross entropy\n",
    "cat_approx = np.array([0.1, 0.2, 0.3, 0.4])\n",
    "\n",
    "# Define a few categorical distributions - Feel free to replace some of these with your own!\n",
    "cat1 = np.array([0.1, 0.2, 0.3, 0.4])  # 4 categories\n",
    "cat2 = np.array([0.25, 0.25, 0.25, 0.25])  # Uniform distribution\n",
    "cat3 = np.array([0.05, 0.15, 0.6, 0.2])  # Slightly skewed towards category 3\n",
    "cat4 = np.array([0.05, 0.05, 0.05, 0.85])  # Dominated by category 4\n",
    "\n",
    "# Add to list and create dummy category names\n",
    "categorical_probabilities = [cat1, cat2, cat3, cat4]\n",
    "categories = np.arange(4)\n",
    "\n",
    "# Calculate empirical entropies\n",
    "categorical_cross_entropies = [theoretical_cross_entropy(categorical, cat_approx) for categorical in categorical_probabilities]\n",
    "\n",
    "# Plot each categorical distribution along with its given empirical entropy\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "axes[0].bar(categories, cat_approx, color=\"mediumslateblue\")\n",
    "axes[0].set_title(\"Approximating distribution\")\n",
    "axes[0].set_xlabel(\"Category\")\n",
    "axes[0].set_ylabel(\"Probability\")\n",
    "\n",
    "for i, (axis, cat_probabilities, cat_entropy, color) in enumerate(zip(axes[1:], categorical_probabilities, categorical_cross_entropies, ['b', 'g', 'r', 'purple'])):\n",
    "    axis.bar(categories, cat_probabilities, color=color)\n",
    "    axis.set_title(f\"Cat {i+1} Empirical Cross-Entropy: {cat_entropy:.2f}\")\n",
    "    axis.set_xlabel(\"Category\")\n",
    "    axis.set_ylabel(\"Probability\")\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #E6E6E6;\">\n",
    "<span style=\"background-color: #00695C; padding:8px; display:block; border-left:4px solid #4682b4\">\n",
    "\n",
    "## $\\star$ Smallish note on *empirical* cross-entropy\n",
    "\n",
    "When calculating cross-entropy for classifiers such as neural networks and multinomial logistic regression, we usually do not have the correct class probabilities $p$, but we do still have our approximate class probabilities $q$. As such, we simply change the class probabiltiies $p$ slightly, to simply be a one-hot vector, indicating what the correct class is. Our formula remains the same, but our probabilities look slighlty different:\n",
    "\n",
    "$$\n",
    "q_i = \n",
    "\\begin{bmatrix}\n",
    "    p_1 \\\\\n",
    "    p_2  \\\\\n",
    "    \\vdots \\\\\n",
    "    p_k \\\\\n",
    "\\end{bmatrix},\n",
    "\n",
    "p_i =\n",
    "\\begin{bmatrix}\n",
    "    0 \\\\\n",
    "    1  \\\\\n",
    "    \\vdots \\\\\n",
    "    0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Above shown in an example where the class of datapoint $i = 2$\n",
    "\n",
    "This is a necessary distinction, as we have no simply way of making a \"counterfactual\" question asking \"What is the probability that the datapoint $i$ would actually be representing as another class c?\". This of course comes with its own host of quirks and downsides, one example being potentially pushing predictions towards extreme overconfidence, always predicting things with 100% accuracy, but in general, it works well enough that we still use it.\n",
    "\n",
    "Bear in mind, many other explanations, like those on the [PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html), for example, also include batch dimensions, which can change the formula just a little bit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signals-and-data-autumn-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
